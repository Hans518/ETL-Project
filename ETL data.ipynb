{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pprint\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us_videos_csv = \"youtube-new/USvideos.csv\"\n",
    "# us_videos_df = pd.read_csv(us_videos_csv)\n",
    "# us_videos_df['country_id'] = \"01\"\n",
    "# us_videos_df.to_csv('resources/us_videos.csv', index=False)\n",
    "# us_videos_df.head()\n",
    "\n",
    "#us_videos_df.head()\n",
    "\n",
    "us_videos_csv = os.path.join('youtube-new/USvideos.csv')\n",
    "\n",
    "video_id = []\n",
    "trending_date = []\n",
    "title = []\n",
    "channel_title = []\n",
    "category_id = []\n",
    "publish_time = []\n",
    "tags = []\n",
    "views = []\n",
    "like = []\n",
    "dislikes = []\n",
    "comment_count = []\n",
    "thumbnail_link = []\n",
    "comments_disabled = []\n",
    "ratings_disabled = []\n",
    "video_error_or_removed = []\n",
    "description = []\n",
    "\n",
    "\n",
    "with open(us_videos_csv, 'r', encoding='ANSI') as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=\",\")\n",
    "    header = next(csvreader)\n",
    "    \n",
    "    for row in csvreader:\n",
    "        try:\n",
    "            video_id.append(row[0])\n",
    "            trending_date.append(row[1])\n",
    "            title.append(row[2])\n",
    "            channel_title.append(row[3])\n",
    "            category_id.append(row[4])\n",
    "            publish_time.append(row[5])\n",
    "            tags.append(row[6])\n",
    "            views.append(row[7])\n",
    "            like.append(row[8])\n",
    "            dislikes.append(row[9])\n",
    "            comment_count.append(row[10])\n",
    "            thumbnail_link.append(row[11])\n",
    "            comments_disabled.append(row[12])\n",
    "            ratings_disabled.append(row[13])\n",
    "            video_error_or_removed.append(row[14])\n",
    "            description.append(row[15])\n",
    "            \n",
    "        except UnicodeDecodeError:\n",
    "            print(\"'utf-8' codec can't decode bytes in position 7838-7839: invalid continuation byte\")\n",
    "            \n",
    "date_data = []\n",
    "\n",
    "for d in trending_date:\n",
    "    try:\n",
    "        date_conv = datetime.datetime.strptime(d, '%y.%d.%m').date()\n",
    "        date_data.append(date_conv)\n",
    "    except ValueError:\n",
    "        date_data.append(\"Backup end not found\")\n",
    "\n",
    "trending_date = date_data\n",
    "\n",
    "        \n",
    "us_videos_df = pd.DataFrame({\n",
    "    \"video_id\" : video_id,\n",
    "    \"trending_date\" : trending_date, \n",
    "    \"title\" : title,\n",
    "    \"channel_title\" : channel_title,\n",
    "    \"category_id\" : category_id,\n",
    "    \"Publish_time\" : publish_time,\n",
    "    \"views\" : views,\n",
    "    \"likes\" : like, \n",
    "    \"dislikes\" : dislikes,\n",
    "    \"comment_count\" : comment_count,\n",
    "})        \n",
    "\n",
    "\n",
    "us_videos_df[\"title\"] = us_videos_df[\"title\"].str.replace(',', '')\n",
    "us_videos_df['country_id'] = \"01\"\n",
    "us_videos_df.to_csv('resources/us_videos.csv', index=False)\n",
    "#us_videos_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://postgres:password@localhost/YouTube_db')\n",
    "us_videos_df.to_sql(name='trending_videos', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ca_videos_csv = \"youtube-new/CAvideos.csv\"\n",
    "# ca_videos_df = pd.read_csv(ca_videos_csv)\n",
    "# ca_videos_df['country_id'] = \"02\"\n",
    "# ca_videos_df.to_csv('resources/ca_videos.csv', index=False)\n",
    "# ca_videos_df.head()\n",
    "\n",
    "ca_videos_csv = os.path.join('youtube-new/CAvideos.csv')\n",
    "\n",
    "video_id = []\n",
    "trending_date = []\n",
    "title = []\n",
    "channel_title = []\n",
    "category_id = []\n",
    "publish_time = []\n",
    "tags = []\n",
    "views = []\n",
    "like = []\n",
    "dislikes = []\n",
    "comment_count = []\n",
    "thumbnail_link = []\n",
    "comments_disabled = []\n",
    "ratings_disabled = []\n",
    "video_error_or_removed = []\n",
    "description = []\n",
    "\n",
    "\n",
    "with open(ca_videos_csv, 'r', encoding='ANSI') as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=\",\")\n",
    "    header = next(csvreader)\n",
    "    \n",
    "    for row in csvreader:\n",
    "        try:\n",
    "            video_id.append(row[0])\n",
    "            trending_date.append(row[1])\n",
    "            title.append(row[2])\n",
    "            channel_title.append(row[3])\n",
    "            category_id.append(row[4])\n",
    "            publish_time.append(row[5])\n",
    "            tags.append(row[6])\n",
    "            views.append(row[7])\n",
    "            like.append(row[8])\n",
    "            dislikes.append(row[9])\n",
    "            comment_count.append(row[10])\n",
    "            thumbnail_link.append(row[11])\n",
    "            comments_disabled.append(row[12])\n",
    "            ratings_disabled.append(row[13])\n",
    "            video_error_or_removed.append(row[14])\n",
    "            description.append(row[15])\n",
    "            \n",
    "        except UnicodeDecodeError:\n",
    "            print(\"'utf-8' codec can't decode bytes in position 7838-7839: invalid continuation byte\")\n",
    "            \n",
    "date_data = []\n",
    "\n",
    "for d in trending_date:\n",
    "    try:\n",
    "        date_conv = datetime.datetime.strptime(d, '%y.%d.%m').date()\n",
    "        date_data.append(date_conv)\n",
    "    except ValueError:\n",
    "        date_data.append(\"Backup end not found\")\n",
    "\n",
    "trending_date = date_data\n",
    "        \n",
    "ca_videos_df = pd.DataFrame({\n",
    "    \"video_id\" : video_id,\n",
    "    \"trending_date\" : trending_date, \n",
    "    \"title\" : title,\n",
    "    \"channel_title\" : channel_title,\n",
    "    \"category_id\" : category_id,\n",
    "    \"Publish_time\" : publish_time,\n",
    "    \"views\" : views,\n",
    "    \"likes\" : like, \n",
    "    \"dislikes\" : dislikes,\n",
    "    \"comment_count\" : comment_count,\n",
    "}) \n",
    "\n",
    "ca_videos_df[\"title\"] = ca_videos_df[\"title\"].str.replace(',', '')\n",
    "ca_videos_df['country_id'] = \"02\"\n",
    "ca_videos_df.to_csv('resources/ca_videos.csv', index=False)\n",
    "#ca_videos_df.head()\n",
    "ca_videos_df.to_sql(name='trending_videos', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = create_engine('postgresql://postgres:password@localhost/YouTube_db')\n",
    "# ca_videos_df.to_sql(name='trending_videos', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de_videos_csv = \"youtube-new/DEvideos.csv\"\n",
    "# de_videos_df = pd.read_csv(de_videos_csv)\n",
    "# de_videos_df['country_id'] = \"03\"\n",
    "# de_videos_df.to_csv('resources/de_videos.csv', index=False)\n",
    "# de_videos_df.head()\n",
    "\n",
    "de_videos_csv = os.path.join('youtube-new/DEvideos.csv')\n",
    "\n",
    "video_id = []\n",
    "trending_date = []\n",
    "title = []\n",
    "channel_title = []\n",
    "category_id = []\n",
    "publish_time = []\n",
    "tags = []\n",
    "views = []\n",
    "like = []\n",
    "dislikes = []\n",
    "comment_count = []\n",
    "thumbnail_link = []\n",
    "comments_disabled = []\n",
    "ratings_disabled = []\n",
    "video_error_or_removed = []\n",
    "description = []\n",
    "\n",
    "\n",
    "with open(de_videos_csv, 'r', encoding='ANSI') as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=\",\")\n",
    "    header = next(csvreader)\n",
    "    \n",
    "    for row in csvreader:\n",
    "        try:\n",
    "            video_id.append(row[0])\n",
    "            trending_date.append(row[1])\n",
    "            title.append(row[2])\n",
    "            channel_title.append(row[3])\n",
    "            category_id.append(row[4])\n",
    "            publish_time.append(row[5])\n",
    "            tags.append(row[6])\n",
    "            views.append(row[7])\n",
    "            like.append(row[8])\n",
    "            dislikes.append(row[9])\n",
    "            comment_count.append(row[10])\n",
    "            thumbnail_link.append(row[11])\n",
    "            comments_disabled.append(row[12])\n",
    "            ratings_disabled.append(row[13])\n",
    "            video_error_or_removed.append(row[14])\n",
    "            description.append(row[15])\n",
    "            \n",
    "        except UnicodeDecodeError:\n",
    "            print(\"'utf-8' codec can't decode bytes in position 7838-7839: invalid continuation byte\")\n",
    "            \n",
    "date_data = []\n",
    "\n",
    "for d in trending_date:\n",
    "    try:\n",
    "        date_conv = datetime.datetime.strptime(d, '%y.%d.%m').date()\n",
    "        date_data.append(date_conv)\n",
    "    except ValueError:\n",
    "        date_data.append(\"Backup end not found\")\n",
    "\n",
    "trending_date = date_data\n",
    "        \n",
    "de_videos_df = pd.DataFrame({\n",
    "    \"video_id\" : video_id,\n",
    "    \"trending_date\" : trending_date, \n",
    "    \"title\" : title,\n",
    "    \"channel_title\" : channel_title,\n",
    "    \"category_id\" : category_id,\n",
    "    \"Publish_time\" : publish_time,\n",
    "    \"views\" : views,\n",
    "    \"likes\" : like, \n",
    "    \"dislikes\" : dislikes,\n",
    "    \"comment_count\" : comment_count\n",
    "}) \n",
    " \n",
    "\n",
    "de_videos_df[\"title\"] = de_videos_df[\"title\"].str.replace(',', '')\n",
    "de_videos_df['country_id'] = \"03\"\n",
    "de_videos_df.to_csv('resources/de_videos.csv', index=False)\n",
    "#de_videos_df.head()\n",
    "de_videos_df.to_sql(name='trending_videos', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = create_engine('postgresql://postgres:password@localhost/YouTube_db')\n",
    "# de_videos_df.to_sql(name='trending_videos', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fr_videos_csv = \"youtube-new/FRvideos.csv\"\n",
    "# fr_videos_df = pd.read_csv(fr_videos_csv)\n",
    "# fr_videos_df['country_id'] = \"04\"\n",
    "# fr_videos_df.to_csv('resources/fr_videos.csv', index=False)\n",
    "# fr_videos_df.head()\n",
    "\n",
    "fr_videos_csv = os.path.join('youtube-new/FRvideos.csv')\n",
    "\n",
    "video_id = []\n",
    "trending_date = []\n",
    "title = []\n",
    "channel_title = []\n",
    "category_id = []\n",
    "publish_time = []\n",
    "tags = []\n",
    "views = []\n",
    "like = []\n",
    "dislikes = []\n",
    "comment_count = []\n",
    "thumbnail_link = []\n",
    "comments_disabled = []\n",
    "ratings_disabled = []\n",
    "video_error_or_removed = []\n",
    "description = []\n",
    "\n",
    "\n",
    "with open(fr_videos_csv, 'r', encoding='ANSI') as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=\",\")\n",
    "    header = next(csvreader)\n",
    "    \n",
    "    for row in csvreader:\n",
    "        try:\n",
    "            video_id.append(row[0])\n",
    "            trending_date.append(row[1])\n",
    "            title.append(row[2])\n",
    "            channel_title.append(row[3])\n",
    "            category_id.append(row[4])\n",
    "            publish_time.append(row[5])\n",
    "            tags.append(row[6])\n",
    "            views.append(row[7])\n",
    "            like.append(row[8])\n",
    "            dislikes.append(row[9])\n",
    "            comment_count.append(row[10])\n",
    "            thumbnail_link.append(row[11])\n",
    "            comments_disabled.append(row[12])\n",
    "            ratings_disabled.append(row[13])\n",
    "            video_error_or_removed.append(row[14])\n",
    "            description.append(row[15])\n",
    "            \n",
    "        except UnicodeDecodeError:\n",
    "            print(\"'utf-8' codec can't decode bytes in position 7838-7839: invalid continuation byte\")\n",
    "            \n",
    "date_data = []\n",
    "\n",
    "for d in trending_date:\n",
    "    try:\n",
    "        date_conv = datetime.datetime.strptime(d, '%y.%d.%m').date()\n",
    "        date_data.append(date_conv)\n",
    "    except ValueError:\n",
    "        date_data.append(\"Backup end not found\")\n",
    "\n",
    "trending_date = date_data\n",
    "        \n",
    "fr_videos_df = pd.DataFrame({\n",
    "    \"video_id\" : video_id,\n",
    "    \"trending_date\" : trending_date, \n",
    "    \"title\" : title,\n",
    "    \"channel_title\" : channel_title,\n",
    "    \"category_id\" : category_id,\n",
    "    \"Publish_time\" : publish_time,\n",
    "    \"views\" : views,\n",
    "    \"likes\" : like, \n",
    "    \"dislikes\" : dislikes,\n",
    "    \"comment_count\" : comment_count\n",
    "}) \n",
    "\n",
    "fr_videos_df[\"title\"] = fr_videos_df[\"title\"].str.replace(',', '')\n",
    "fr_videos_df['country_id'] = \"04\"\n",
    "fr_videos_df.to_csv('resources/fr_videos.csv', index=False)\n",
    "#fr_videos_df.head()\n",
    "fr_videos_df.to_sql(name='trending_videos', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = create_engine('postgresql://postgres:password@localhost/YouTube_db')\n",
    "# de_videos_df.to_sql(name='trending_videos', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gb_videos_csv = \"youtube-new/GBvideos.csv\"\n",
    "# gb_videos_df = pd.read_csv(gb_videos_csv)\n",
    "# gb_videos_df['country_id'] = \"05\"\n",
    "# gb_videos_df.to_csv('resources/gb_videos.csv', index=False)\n",
    "# gb_videos_df.head()\n",
    "\n",
    "gb_videos_csv = os.path.join('youtube-new/GBvideos.csv')\n",
    "\n",
    "video_id = []\n",
    "trending_date = []\n",
    "title = []\n",
    "channel_title = []\n",
    "category_id = []\n",
    "publish_time = []\n",
    "tags = []\n",
    "views = []\n",
    "like = []\n",
    "dislikes = []\n",
    "comment_count = []\n",
    "thumbnail_link = []\n",
    "comments_disabled = []\n",
    "ratings_disabled = []\n",
    "video_error_or_removed = []\n",
    "description = []\n",
    "\n",
    "\n",
    "with open(gb_videos_csv, 'r', encoding='ANSI') as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=\",\")\n",
    "    header = next(csvreader)\n",
    "    \n",
    "    for row in csvreader:\n",
    "        try:\n",
    "            video_id.append(row[0])\n",
    "            trending_date.append(row[1])\n",
    "            title.append(row[2])\n",
    "            channel_title.append(row[3])\n",
    "            category_id.append(row[4])\n",
    "            publish_time.append(row[5])\n",
    "            tags.append(row[6])\n",
    "            views.append(row[7])\n",
    "            like.append(row[8])\n",
    "            dislikes.append(row[9])\n",
    "            comment_count.append(row[10])\n",
    "            thumbnail_link.append(row[11])\n",
    "            comments_disabled.append(row[12])\n",
    "            ratings_disabled.append(row[13])\n",
    "            video_error_or_removed.append(row[14])\n",
    "            description.append(row[15])\n",
    "            \n",
    "        except UnicodeDecodeError:\n",
    "            print(\"'utf-8' codec can't decode bytes in position 7838-7839: invalid continuation byte\")\n",
    "            \n",
    "date_data = []\n",
    "\n",
    "for d in trending_date:\n",
    "    try:\n",
    "        date_conv = datetime.datetime.strptime(d, '%y.%d.%m').date()\n",
    "        date_data.append(date_conv)\n",
    "    except ValueError:\n",
    "        date_data.append(\"Backup end not found\")\n",
    "\n",
    "trending_date = date_data\n",
    "        \n",
    "gb_videos_df = pd.DataFrame({\n",
    "    \"video_id\" : video_id,\n",
    "    \"trending_date\" : trending_date, \n",
    "    \"title\" : title,\n",
    "    \"channel_title\" : channel_title,\n",
    "    \"category_id\" : category_id,\n",
    "    \"Publish_time\" : publish_time,\n",
    "    \"views\" : views,\n",
    "    \"likes\" : like, \n",
    "    \"dislikes\" : dislikes,\n",
    "    \"comment_count\" : comment_count\n",
    "}) \n",
    "\n",
    "gb_videos_df[\"title\"] = gb_videos_df[\"title\"].str.replace(',', '')\n",
    "gb_videos_df['country_id'] = \"05\"\n",
    "gb_videos_df.to_csv('resources/gb_videos.csv', index=False)\n",
    "#gb_videos_df.head()\n",
    "gb_videos_df.to_sql(name='trending_videos', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = create_engine('postgresql://postgres:password@localhost/YouTube_db')\n",
    "# de_videos_df.to_sql(name='trending_videos', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>Publish_time</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>country_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jw1Y-zhQURU</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>John Lewis Christmas Ad 2017 - #MozTheMonster</td>\n",
       "      <td>John Lewis</td>\n",
       "      <td>26</td>\n",
       "      <td>2017-11-10T07:38:29.000Z</td>\n",
       "      <td>7224515</td>\n",
       "      <td>55681</td>\n",
       "      <td>10247</td>\n",
       "      <td>9479</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3s1rvMFUweQ</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>Taylor Swift: â€¦Ready for It? (Live) - SNL</td>\n",
       "      <td>Saturday Night Live</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-12T06:24:44.000Z</td>\n",
       "      <td>1053632</td>\n",
       "      <td>25561</td>\n",
       "      <td>2294</td>\n",
       "      <td>2757</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n1WpP7iowLc</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>Eminem - Walk On Water (Audio) ft. BeyoncÃ©</td>\n",
       "      <td>EminemVEVO</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-11-10T17:00:03.000Z</td>\n",
       "      <td>17158579</td>\n",
       "      <td>787420</td>\n",
       "      <td>43420</td>\n",
       "      <td>125882</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUTEiSjKwJU</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>Goals from Salford City vs Class of 92 and Fri...</td>\n",
       "      <td>Salford City Football Club</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-11-13T02:30:38.000Z</td>\n",
       "      <td>27833</td>\n",
       "      <td>193</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rHwDegptbI4</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>Dashcam captures truck's near miss with child ...</td>\n",
       "      <td>Cute Girl Videos</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-11-13T01:45:13.000Z</td>\n",
       "      <td>9815</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  Jw1Y-zhQURU    2017-11-14   \n",
       "1  3s1rvMFUweQ    2017-11-14   \n",
       "2  n1WpP7iowLc    2017-11-14   \n",
       "3  PUTEiSjKwJU    2017-11-14   \n",
       "4  rHwDegptbI4    2017-11-14   \n",
       "\n",
       "                                               title  \\\n",
       "0      John Lewis Christmas Ad 2017 - #MozTheMonster   \n",
       "1        Taylor Swift: â€¦Ready for It? (Live) - SNL   \n",
       "2        Eminem - Walk On Water (Audio) ft. BeyoncÃ©   \n",
       "3  Goals from Salford City vs Class of 92 and Fri...   \n",
       "4  Dashcam captures truck's near miss with child ...   \n",
       "\n",
       "                channel_title category_id              Publish_time     views  \\\n",
       "0                  John Lewis          26  2017-11-10T07:38:29.000Z   7224515   \n",
       "1         Saturday Night Live          24  2017-11-12T06:24:44.000Z   1053632   \n",
       "2                  EminemVEVO          10  2017-11-10T17:00:03.000Z  17158579   \n",
       "3  Salford City Football Club          17  2017-11-13T02:30:38.000Z     27833   \n",
       "4            Cute Girl Videos          25  2017-11-13T01:45:13.000Z      9815   \n",
       "\n",
       "    likes dislikes comment_count country_id  \n",
       "0   55681    10247          9479         05  \n",
       "1   25561     2294          2757         05  \n",
       "2  787420    43420        125882         05  \n",
       "3     193       12            37         05  \n",
       "4      30        2            30         05  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_videos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_videos_csv = \"youtube-new/INvideos.csv\"\n",
    "# in_videos_df = pd.read_csv(in_videos_csv)\n",
    "# in_videos_df['country_id'] = \"06\"\n",
    "# in_videos_df.to_csv('resources/in_videos.csv', index=False)\n",
    "# in_videos_df.head()\n",
    "\n",
    "in_videos_csv = os.path.join('youtube-new/INvideos.csv')\n",
    "\n",
    "video_id = []\n",
    "trending_date = []\n",
    "title = []\n",
    "channel_title = []\n",
    "category_id = []\n",
    "publish_time = []\n",
    "tags = []\n",
    "views = []\n",
    "like = []\n",
    "dislikes = []\n",
    "comment_count = []\n",
    "thumbnail_link = []\n",
    "comments_disabled = []\n",
    "ratings_disabled = []\n",
    "video_error_or_removed = []\n",
    "description = []\n",
    "\n",
    "\n",
    "with open(in_videos_csv, 'r', encoding='ANSI') as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=\",\")\n",
    "    header = next(csvreader)\n",
    "    \n",
    "    for row in csvreader:\n",
    "        try:\n",
    "            video_id.append(row[0])\n",
    "            trending_date.append(row[1])\n",
    "            title.append(row[2])\n",
    "            channel_title.append(row[3])\n",
    "            category_id.append(row[4])\n",
    "            publish_time.append(row[5])\n",
    "            tags.append(row[6])\n",
    "            views.append(row[7])\n",
    "            like.append(row[8])\n",
    "            dislikes.append(row[9])\n",
    "            comment_count.append(row[10])\n",
    "            thumbnail_link.append(row[11])\n",
    "            comments_disabled.append(row[12])\n",
    "            ratings_disabled.append(row[13])\n",
    "            video_error_or_removed.append(row[14])\n",
    "            description.append(row[15])\n",
    "            \n",
    "        except UnicodeDecodeError:\n",
    "            print(\"'utf-8' codec can't decode bytes in position 7838-7839: invalid continuation byte\")\n",
    "            \n",
    "date_data = []\n",
    "\n",
    "for d in trending_date:\n",
    "    try:\n",
    "        date_conv = datetime.datetime.strptime(d, '%y.%d.%m').date()\n",
    "        date_data.append(date_conv)\n",
    "    except ValueError:\n",
    "        date_data.append(\"Backup end not found\")\n",
    "\n",
    "trending_date = date_data\n",
    "        \n",
    "in_videos_df = pd.DataFrame({\n",
    "    \"video_id\" : video_id,\n",
    "    \"trending_date\" : trending_date, \n",
    "    \"title\" : title,\n",
    "    \"channel_title\" : channel_title,\n",
    "    \"category_id\" : category_id,\n",
    "    \"Publish_time\" : publish_time,\n",
    "    \"views\" : views,\n",
    "    \"likes\" : like, \n",
    "    \"dislikes\" : dislikes,\n",
    "    \"comment_count\" : comment_count\n",
    "}) \n",
    "\n",
    "in_videos_df[\"title\"] = in_videos_df[\"title\"].str.replace(',', '')\n",
    "in_videos_df['country_id'] = \"06\"\n",
    "in_videos_df.to_csv('resources/in_videos.csv', index=False)\n",
    "#in_videos_df.head()\n",
    "in_videos_df.to_sql(name='trending_videos', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = create_engine('postgresql://postgres:password@localhost/YouTube_db')\n",
    "# de_videos_df.to_sql(name='trending_videos', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mx_videos_csv = \"youtube-new/MXvideos.csv\"\n",
    "# mx_videos_df = pd.read_csv(mx_videos_csv,  encoding='ANSI')\n",
    "# mx_videos_df['country_id'] = \"07\"\n",
    "# mx_videos_df.to_csv('resources/mx_videos.csv', index=False)\n",
    "# mx_videos_df.head()\n",
    "\n",
    "mx_videos_csv = os.path.join('youtube-new/MXvideos.csv')\n",
    "\n",
    "video_id = []\n",
    "trending_date = []\n",
    "title = []\n",
    "channel_title = []\n",
    "category_id = []\n",
    "publish_time = []\n",
    "tags = []\n",
    "views = []\n",
    "like = []\n",
    "dislikes = []\n",
    "comment_count = []\n",
    "thumbnail_link = []\n",
    "comments_disabled = []\n",
    "ratings_disabled = []\n",
    "video_error_or_removed = []\n",
    "description = []\n",
    "\n",
    "\n",
    "with open(mx_videos_csv, 'r', encoding='ANSI') as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=\",\")\n",
    "    header = next(csvreader)\n",
    "    \n",
    "    for row in csvreader:\n",
    "        try:\n",
    "            video_id.append(row[0])\n",
    "            trending_date.append(row[1])\n",
    "            title.append(row[2])\n",
    "            channel_title.append(row[3])\n",
    "            category_id.append(row[4])\n",
    "            publish_time.append(row[5])\n",
    "            tags.append(row[6])\n",
    "            views.append(row[7])\n",
    "            like.append(row[8])\n",
    "            dislikes.append(row[9])\n",
    "            comment_count.append(row[10])\n",
    "            thumbnail_link.append(row[11])\n",
    "            comments_disabled.append(row[12])\n",
    "            ratings_disabled.append(row[13])\n",
    "            video_error_or_removed.append(row[14])\n",
    "            description.append(row[15])\n",
    "            \n",
    "        except UnicodeDecodeError:\n",
    "            print(\"'utf-8' codec can't decode bytes in position 7838-7839: invalid continuation byte\")\n",
    "            \n",
    "date_data = []\n",
    "\n",
    "for d in trending_date:\n",
    "    try:\n",
    "        date_conv = datetime.datetime.strptime(d, '%y.%d.%m').date()\n",
    "        date_data.append(date_conv)\n",
    "    except ValueError:\n",
    "        date_data.append(\"Backup end not found\")\n",
    "\n",
    "trending_date = date_data\n",
    "        \n",
    "mx_videos_df = pd.DataFrame({\n",
    "    \"video_id\" : video_id,\n",
    "    \"trending_date\" : trending_date, \n",
    "    \"title\" : title,\n",
    "    \"channel_title\" : channel_title,\n",
    "    \"category_id\" : category_id,\n",
    "    \"Publish_time\" : publish_time,\n",
    "    \"views\" : views,\n",
    "    \"likes\" : like, \n",
    "    \"dislikes\" : dislikes,\n",
    "    \"comment_count\" : comment_count\n",
    "}) \n",
    "\n",
    "mx_videos_df[\"title\"] = mx_videos_df[\"title\"].str.replace(',', '')\n",
    "mx_videos_df['country_id'] = \"07\"\n",
    "mx_videos_df.to_csv('resources/mx_videos.csv', index=False)\n",
    "#mx_videos_df.head()\n",
    "mx_videos_df.to_sql(name='trending_videos', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = create_engine('postgresql://postgres:password@localhost/YouTube_db')\n",
    "# de_videos_df.to_sql(name='trending_videos', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jp_videos_csv = \"youtube-new/JPvideos.csv\"\n",
    "# jp_videos_df = pd.read_csv(jp_videos_csv, encoding='cp850')\n",
    "# jp_videos_df.head(50)\n",
    "\n",
    "# jp_videos_csv = os.path.join('youtube-new/JPvideos.csv')\n",
    "\n",
    "# video_id = []\n",
    "# trending_date = []\n",
    "# title = []\n",
    "# channel_title = []\n",
    "# category_id = []\n",
    "# publish_time = []\n",
    "# tags = []\n",
    "# views = []\n",
    "# like = []\n",
    "# dislikes = []\n",
    "# comment_count = []\n",
    "# thumbnail_link = []\n",
    "# comments_disabled = []\n",
    "# ratings_disabled = []\n",
    "# video_error_or_removed = []\n",
    "# description = []\n",
    "\n",
    "\n",
    "# with open(jp_videos_csv, 'r', encoding='utf_32') as csvfile:\n",
    "#     csvreader = csv.reader(csvfile, delimiter=\",\")\n",
    "#     header = next(csvreader)\n",
    "    \n",
    "#     for row in csvreader:\n",
    "#         try:\n",
    "#             video_id.append(row[0])\n",
    "#             trending_date.append(row[1])\n",
    "#             title.append(row[2])\n",
    "#             channel_title.append(row[3])\n",
    "#             publish_time.append(row[4])\n",
    "#             tags.append(row[5])\n",
    "#             views.append(row[6])\n",
    "#             like.append(row[7])\n",
    "#             dislikes.append(row[8])\n",
    "#             comment_count.append(row[9])\n",
    "#             thumbnail_link.append(row[10])\n",
    "#             comments_disabled.append(row[11])\n",
    "#             ratings_disabled.append(row[12])\n",
    "#             video_error_or_removed.append(row[13])\n",
    "#             description.append(row[14])\n",
    "            \n",
    "#         except UnicodeDecodeError:\n",
    "#             print(\"'utf-8' codec can't decode bytes in position 7838-7839: invalid continuation byte\")\n",
    "          \n",
    "# date_data = []\n",
    "# for d in term_date:\n",
    "#     try:\n",
    "#         date_conv = datetime.datetime.strptime(d, '%m/%d/%Y').date()\n",
    "#         date_data.append(date_conv)\n",
    "#     except ValueError:\n",
    "#         date_data.append(\"Backup end not found\")\n",
    "\n",
    "# term_date = date_data\n",
    "\n",
    "# termed_workers_df = pd.DataFrame({\"First Name\" : first,\n",
    "#                                  \"Last Name\" : last,\n",
    "#                                  \"Email\": email,\n",
    "#                                  \"term_date\" : term_date})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kr_videos_csv = \"youtube-new/KRvideos.csv\"\n",
    "# kr_videos_df = pd.read_csv(kr_videos_csv)\n",
    "# kr_videos_df.head(50)\n",
    "\n",
    "# kr_videos_csv = os.path.join('youtube-new/KRvideos.csv')\n",
    "\n",
    "# video_id = []\n",
    "# trending_date = []\n",
    "# title = []\n",
    "# channel_title = []\n",
    "# category_id = []\n",
    "# publish_time = []\n",
    "# tags = []\n",
    "# views = []\n",
    "# like = []\n",
    "# dislikes = []\n",
    "# comment_count = []\n",
    "# thumbnail_link = []\n",
    "# comments_disabled = []\n",
    "# ratings_disabled = []\n",
    "# video_error_or_removed = []\n",
    "# description = []\n",
    "\n",
    "\n",
    "# with open(kr_videos_csv, 'r', encoding='iso2022_kr') as csvfile:\n",
    "#     csvreader = csv.reader(csvfile, delimiter=\",\")\n",
    "#     header = next(csvreader)\n",
    "    \n",
    "#     for row in csvreader:\n",
    "#         try:\n",
    "#             video_id.append(row[0])\n",
    "#             trending_date.append(row[1])\n",
    "#             title.append(row[2])\n",
    "#             channel_title.append(row[3])\n",
    "#             publish_time.append(row[4])\n",
    "#             tags.append(row[5])\n",
    "#             views.append(row[6])\n",
    "#             like.append(row[7])\n",
    "#             dislikes.append(row[8])\n",
    "#             comment_count.append(row[9])\n",
    "#             thumbnail_link.append(row[10])\n",
    "#             comments_disabled.append(row[11])\n",
    "#             ratings_disabled.append(row[12])\n",
    "#             video_error_or_removed.append(row[13])\n",
    "#             description.append(row[14])\n",
    "            \n",
    "#         except UnicodeDecodeError:\n",
    "#             print(\"'utf-8' codec can't decode bytes in position 7838-7839: invalid continuation byte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ru_videos_csv = \"youtube-new/RUvideos.csv\"\n",
    "# ru_videos_df = pd.read_csv(ru_videos_csv, encoding='cp866')\n",
    "# ru_videos_df.head(50)\n",
    "# ru_videos_csv = os.path.join('youtube-new/RUvideos.csv')\n",
    "\n",
    "# video_id = []\n",
    "# trending_date = []\n",
    "# title = []\n",
    "# channel_title = []\n",
    "# category_id = []\n",
    "# publish_time = []\n",
    "# tags = []\n",
    "# views = []\n",
    "# like = []\n",
    "# dislikes = []\n",
    "# comment_count = []\n",
    "# thumbnail_link = []\n",
    "# comments_disabled = []\n",
    "# ratings_disabled = []\n",
    "# video_error_or_removed = []\n",
    "# description = []\n",
    "\n",
    "\n",
    "# with open(ru_videos_csv, 'r', encoding='utf-8') as csvfile:\n",
    "#     csvreader = csv.reader(csvfile, delimiter=\",\")\n",
    "#     header = next(csvreader)\n",
    "    \n",
    "#     for row in csvreader:\n",
    "#         print(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_videos_json = open('youtube-new/US_category_id.json')\n",
    "data = json.load(us_videos_json)\n",
    "video_categories = data['items']\n",
    "\n",
    "#pprint.pprint(video_categories)\n",
    "\n",
    "etag = []\n",
    "id = []\n",
    "kind = []\n",
    "assignable = []\n",
    "channelId = []\n",
    "title = []\n",
    "snippet = []\n",
    "\n",
    "for x in video_categories: \n",
    "    etag.append(x['etag'])\n",
    "    id.append(x['id'])\n",
    "    snippet.append(x['snippet'])\n",
    "    \n",
    "for s in snippet:\n",
    "    title.append(s['title'])\n",
    "    \n",
    "\n",
    "categories = pd.DataFrame({\"category_id\" : id,\n",
    "                          \"category_name\" : title})\n",
    "\n",
    "#categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ca_videos_json = open('youtube-new/CA_category_id.json')\n",
    "# data = json.load(ca_videos_json)\n",
    "# video_categories = data['items']\n",
    "\n",
    "# #pprint.pprint(video_categories)\n",
    "\n",
    "# etag = []\n",
    "# id = []\n",
    "# kind = []\n",
    "# assignable = []\n",
    "# channelId = []\n",
    "# title = []\n",
    "# snippet = []\n",
    "\n",
    "# for x in video_categories: \n",
    "#     etag.append(x['etag'])\n",
    "#     id.append(x['id'])\n",
    "#     snippet.append(x['snippet'])\n",
    "    \n",
    "# for s in snippet:\n",
    "#     title.append(s['title'])\n",
    "    \n",
    "\n",
    "# categories = pd.DataFrame({\"category_id\" : id,\n",
    "#                           \"category_name\" : title})\n",
    "\n",
    "#categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
